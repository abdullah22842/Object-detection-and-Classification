{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a612ce44",
   "metadata": {},
   "source": [
    "# Image Classification and Object Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this lab, you'll build a CNN from scratch to:\n",
    "\n",
    "# classify the main subject in an image\n",
    "# localize it by drawing bounding boxes around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import  \n",
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb30e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "\n",
    "\n",
    "#@title Plot Utilities for Bounding Boxes [RUN ME]\n",
    "\n",
    "im_width = 75\n",
    "im_height = 75\n",
    "use_normalized_coordinates = True\n",
    "\n",
    "def draw_bounding_boxes_on_image_array(image,\n",
    "                                       boxes,\n",
    "                                       color=[],\n",
    "                                       thickness=1,\n",
    "                                       display_str_list=()):\n",
    "  \"\"\"Draws bounding boxes on image (numpy array).\n",
    "  Args:\n",
    "    image: a numpy array object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list_list: a list of strings for each bounding box.\n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  image_pil = PIL.Image.fromarray(image)\n",
    "  rgbimg = PIL.Image.new(\"RGBA\", image_pil.size)\n",
    "  rgbimg.paste(image_pil)\n",
    "  draw_bounding_boxes_on_image(rgbimg, boxes, color, thickness,\n",
    "                               display_str_list)\n",
    "  return np.array(rgbimg)\n",
    "  \n",
    "\n",
    "def draw_bounding_boxes_on_image(image,\n",
    "                                 boxes,\n",
    "                                 color=[],\n",
    "                                 thickness=1,\n",
    "                                 display_str_list=()):\n",
    "  \"\"\"Draws bounding boxes on image.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
    "           The coordinates are in normalized format between [0, 1].\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: a list of strings for each bounding box.\n",
    "                           \n",
    "  Raises:\n",
    "    ValueError: if boxes is not a [N, 4] array\n",
    "  \"\"\"\n",
    "  boxes_shape = boxes.shape\n",
    "  if not boxes_shape:\n",
    "    return\n",
    "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
    "    raise ValueError('Input must be of size [N, 4]')\n",
    "  for i in range(boxes_shape[0]):\n",
    "    draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3],\n",
    "                               boxes[i, 2], color[i], thickness, display_str_list[i])\n",
    "        \n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=1,\n",
    "                               display_str=None,\n",
    "                               use_normalized_coordinates=True):\n",
    "  \"\"\"Adds a bounding box to an image.\n",
    "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
    "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
    "  Args:\n",
    "    image: a PIL.Image object.\n",
    "    ymin: ymin of bounding box.\n",
    "    xmin: xmin of bounding box.\n",
    "    ymax: ymax of bounding box.\n",
    "    xmax: xmax of bounding box.\n",
    "    color: color to draw bounding box. Default is red.\n",
    "    thickness: line thickness. Default value is 4.\n",
    "    display_str_list: string to display in box\n",
    "    use_normalized_coordinates: If True (default), treat coordinates\n",
    "      ymin, xmin, ymax, xmax as relative to the image.  Otherwise treat\n",
    "      coordinates as absolute.\n",
    "  \"\"\"\n",
    "  draw = PIL.ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width=thickness, fill=color)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contains helper functions used for visualization\n",
    "and downloads only. \n",
    "\n",
    "You can skip reading it, as there is very\n",
    "little Keras or Tensorflow related code here.\n",
    "\"\"\"\n",
    "\n",
    "# Matplotlib config\n",
    "\n",
    "plt.rc('image', cmap='gray')\n",
    "plt.rc('grid', linewidth=0)\n",
    "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
    "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
    "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
    "plt.rc('text', color='a8151a')\n",
    "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
    "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
    "\n",
    "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
    "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
    "  \n",
    "  # get one batch from each: 10000 validation digits, N training digits\n",
    "  batch_train_ds = training_dataset.unbatch().batch(N)\n",
    "  \n",
    "  # eager execution: loop through datasets normally\n",
    "  if tf.executing_eagerly():\n",
    "    for validation_digits, (validation_labels, validation_bboxes) in validation_dataset:\n",
    "      validation_digits = validation_digits.numpy()\n",
    "      validation_labels = validation_labels.numpy()\n",
    "      validation_bboxes = validation_bboxes.numpy()\n",
    "      break\n",
    "    for training_digits, (training_labels, training_bboxes) in batch_train_ds:\n",
    "      training_digits = training_digits.numpy()\n",
    "      training_labels = training_labels.numpy()\n",
    "      training_bboxes = training_bboxes.numpy()\n",
    "      break\n",
    "  \n",
    "  # these were one-hot encoded in the dataset\n",
    "  validation_labels = np.argmax(validation_labels, axis=1)\n",
    "  training_labels = np.argmax(training_labels, axis=1)\n",
    "  \n",
    "  return (training_digits, training_labels, training_bboxes,\n",
    "          validation_digits, validation_labels, validation_bboxes)\n",
    "\n",
    "# create digits from local fonts for testing\n",
    "def create_digits_from_local_fonts(n):\n",
    "  font_labels = []\n",
    "  img = PIL.Image.new('LA', (75*n, 75), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
    "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
    "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
    "  d = PIL.ImageDraw.Draw(img)\n",
    "  for i in range(n):\n",
    "    font_labels.append(i%10)\n",
    "    d.text((7+i*75,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
    "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
    "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [75, 75*n]), n, axis=1), axis=0), [n, 75*75])\n",
    "  return font_digits, font_labels\n",
    "\n",
    "\n",
    "# utility to display a row of digits with their predictions\n",
    "def display_digits_with_boxes(digits, predictions, labels, pred_bboxes, bboxes, iou, title):\n",
    "\n",
    "  n = 10\n",
    "\n",
    "  indexes = np.random.choice(len(predictions), size=n)\n",
    "  n_digits = digits[indexes]\n",
    "  n_predictions = predictions[indexes]\n",
    "  n_labels = labels[indexes]\n",
    "\n",
    "  n_iou = []\n",
    "  if len(iou) > 0:\n",
    "    n_iou = iou[indexes]\n",
    "\n",
    "  if (len(pred_bboxes) > 0):\n",
    "    n_pred_bboxes = pred_bboxes[indexes,:]\n",
    "\n",
    "  if (len(bboxes) > 0):\n",
    "    n_bboxes = bboxes[indexes,:]\n",
    "\n",
    "\n",
    "  n_digits = n_digits * 255.0\n",
    "  n_digits = n_digits.reshape(n, 75, 75)\n",
    "  fig = plt.figure(figsize=(20, 4))\n",
    "  plt.title(title)\n",
    "  plt.yticks([])\n",
    "  plt.xticks([])\n",
    "  \n",
    "  for i in range(10):\n",
    "    ax = fig.add_subplot(1, 10, i+1)\n",
    "    bboxes_to_plot = []\n",
    "    if (len(pred_bboxes) > i):\n",
    "      bboxes_to_plot.append(n_pred_bboxes[i])\n",
    "    \n",
    "    if (len(bboxes) > i):\n",
    "      bboxes_to_plot.append(n_bboxes[i])\n",
    "\n",
    "    img_to_draw = draw_bounding_boxes_on_image_array(image=n_digits[i], boxes=np.asarray(bboxes_to_plot), color=['red', 'green'], display_str_list=[\"true\", \"pred\"])\n",
    "    plt.xlabel(n_predictions[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if n_predictions[i] != n_labels[i]:\n",
    "      ax.xaxis.label.set_color('red')\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.imshow(img_to_draw)\n",
    "\n",
    "    if len(iou) > i :\n",
    "      color = \"black\"\n",
    "      if (n_iou[i][0] < iou_threshold):\n",
    "        color = \"red\"\n",
    "      ax.text(0.2, -0.3, \"iou: %s\" %(n_iou[i][0]), color=color, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# utility to display training and validation curves\n",
    "def plot_metrics(metric_name, title, ylim=5):\n",
    "  plt.title(title)\n",
    "  plt.ylim(0,ylim)\n",
    "  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
    "  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f866f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('/tmp/cats-v-dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ce76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Select appropriate distribution strategy\n",
    "if tpu:\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
    "elif len(gpus) > 1:\n",
    "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
    "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "  print('Running on single GPU ', gpus[0].name)\n",
    "else:\n",
    "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "  print('Running on CPU')\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 * strategy.num_replicas_in_sync # Gobal batch size.\n",
    "# The global batch size will be automatically sharded across all\n",
    "# replicas by the tf.data.Dataset API. A single TPU has 8 cores.\n",
    "# The best practice is to scale the batch size by the numb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transforms each image in dataset by pasting it on a 75x75 canvas at random locations.\n",
    "'''\n",
    "def read_image_tfds(image, label):\n",
    "    xmin = tf.random.uniform((), 0 , 48, dtype=tf.int32)\n",
    "    ymin = tf.random.uniform((), 0 , 48, dtype=tf.int32)\n",
    "    image = tf.reshape(image, (28,28,1,))\n",
    "    image = tf.image.pad_to_bounding_box(image, ymin, xmin, 75, 75)\n",
    "    image = tf.cast(image, tf.float32)/255.0\n",
    "    xmin = tf.cast(xmin, tf.float32)\n",
    "    ymin = tf.cast(ymin, tf.float32)\n",
    "   \n",
    "    xmax = (xmin + 28) / 75\n",
    "    ymax = (ymin + 28) / 75\n",
    "    xmin = xmin / 75\n",
    "    ymin = ymin / 75\n",
    "    return image, (tf.one_hot(label, 10), [xmin, ymin, xmax, ymax])\n",
    "  \n",
    "'''\n",
    "Loads and maps the training split of the dataset using the map function. Note that we try to load the gcs version since TPU can only work with datasets on Google Cloud Storage.\n",
    "'''\n",
    "def get_training_dataset():\n",
    "      \n",
    "      with  strategy.scope():\n",
    "        dataset = tfds.load(\"mnist\", split=\"train\", as_supervised=True, try_gcs=True)\n",
    "        dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
    "        dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
    "        dataset = dataset.repeat() # Mandatory for Keras for now\n",
    "        dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
    "        dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
    "      return dataset\n",
    "\n",
    "'''\n",
    "Loads and maps the validation split of the dataset using the map function. Note that we try to load the gcs version since TPU can only work with datasets on Google Cloud Storage.\n",
    "'''  \n",
    "def get_validation_dataset():\n",
    "    dataset = tfds.load(\"mnist\", split=\"test\", as_supervised=True, try_gcs=True)\n",
    "    dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
    "\n",
    "    #dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n",
    "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
    "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
    "    return dataset\n",
    "\n",
    "# instantiate the datasets\n",
    "with strategy.scope():\n",
    "  training_dataset = get_training_dataset()\n",
    "  validation_dataset = get_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd811f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
